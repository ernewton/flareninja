{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# note celerite is linear with N, so no benefit to breaking into chunks\n",
    "# if I wanted to fit two datasets at the same time, I would need to \n",
    "# create a new jitter term that has different variances for the the\n",
    "# different data sets. Harder if assume different amplitudes for two\n",
    "# datasets.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import emcee\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.stats import LombScargle, median_absolute_deviation\n",
    "from scipy.optimize import minimize\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import corner\n",
    "\n",
    "import celerite\n",
    "from celerite import terms\n",
    "\n",
    "from gp import get_rotation_gp\n",
    "from astropy.io import fits\n",
    "from statsmodels import robust\n",
    "import k2plr\n",
    "\n",
    "do_kep = False\n",
    "do_kep2 = False\n",
    "do_kep3 = True\n",
    "do_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if do_kep:\n",
    "    f = fits.open('../data/kplr009726699-2010203174610_slc.fits') \n",
    "    hdu_data = f[1].data\n",
    "\n",
    "    t = hdu_data[\"time\"]\n",
    "    y = hdu_data[\"sap_flux\"]/np.nanmedian(hdu_data[\"sap_flux\"])-1\n",
    "    yerr = hdu_data[\"sap_flux_err\"]/np.nanmedian(hdu_data[\"sap_flux\"])\n",
    "\n",
    "    ninc = 5000\n",
    "    rand = 0 #np.random.randint(0,len(t)-ninc)\n",
    "    t = t[rand:rand+ninc]\n",
    "    y = y[rand:rand+ninc]\n",
    "    yerr = yerr[rand:rand+ninc]\n",
    "\n",
    "    name = f[0].header['OBJECT'].replace(' ','')\n",
    "\n",
    "elif do_kep2:\n",
    "    f = fits.open('../data/kplr009726699-2009350155506_llc.fits') \n",
    "    hdu_data = f[1].data\n",
    "\n",
    "    t = hdu_data[\"time\"]\n",
    "    y = hdu_data[\"sap_flux\"]/np.nanmedian(hdu_data[\"sap_flux\"])-1\n",
    "    yerr = hdu_data[\"sap_flux_err\"]/np.nanmedian(hdu_data[\"sap_flux\"])\n",
    "\n",
    "    #ninc = 5000\n",
    "    #rand = 0 #np.random.randint(0,len(t)-ninc)\n",
    "    #t = t[rand:rand+ninc]\n",
    "    #y = y[rand:rand+ninc]\n",
    "    #yerr = yerr[rand:rand+ninc]\n",
    "\n",
    "    mask = hdu_data[\"sap_quality\"] == 0\n",
    "    t = t[mask]\n",
    "    y = y[mask]\n",
    "    yerr = yerr[mask]\n",
    "    \n",
    "    name = f[0].header['OBJECT'].replace(' ','')\n",
    "\n",
    "elif do_kep3:\n",
    "    k = 9726699\n",
    "    kclient = k2plr.API()\n",
    "    if k>100000000: \n",
    "        star = kclient.k2_star(k) ## K2\n",
    "    else:\n",
    "        star = kclient.star(k) # Kepler\n",
    "\n",
    "    lcs = star.get_light_curves(short_cadence=False)\n",
    "\n",
    "    quarters = np.zeros_like(lcs, dtype=int)\n",
    "    for i, lc in enumerate(lcs):\n",
    "        hdu_list = lc.open()\n",
    "        quarters[i] = hdu_list[0].header['QUARTER']\n",
    "        hdu_list.close()\n",
    "\n",
    "    qq, = np.where(quarters == 9)\n",
    "    \n",
    "    lc = lcs[qq[0]]\n",
    "    with lc.open() as f:\n",
    "        hdu_data = f[1].data\n",
    "        time = hdu_data[\"time\"]\n",
    "        flux = hdu_data[\"sap_flux\"]/np.nanmedian(hdu_data[\"sap_flux\"])-1.\n",
    "        ferr = hdu_data[\"sap_flux_err\"]/np.nanmedian(hdu_data[\"sap_flux\"])\n",
    "        mask = hdu_data[\"sap_quality\"] == 0\n",
    "        name = f[0].header['OBJECT'].replace(' ','')\n",
    "        \n",
    "        t = t[mask]\n",
    "        y = y[mask]\n",
    "        yerr = yerr[mask]\n",
    "   \n",
    "    \n",
    "    \n",
    "elif do_test:\n",
    "    \n",
    "    t, y = np.genfromtxt('/Volumes/Mimas/full_dataset/final/lightcurve_0289.txt',\n",
    "                        unpack=True)\n",
    "    y = y/np.median(y) - 1.\n",
    "    err_est = robust.mad(np.diff(y)) \n",
    "    ## should multiple by 1.48, and then divide by sqrt(2) so pretty much good as is\n",
    "    yerr = np.ones_like(y)*err_est\n",
    "\n",
    "    ninc = 5000\n",
    "    rand = 0 #np.random.randint(0,len(t)-ninc)\n",
    "    t = t[rand:rand+ninc]\n",
    "    y = y[rand:rand+ninc]\n",
    "    yerr = yerr[rand:rand+ninc]\n",
    "    \n",
    "    name = '0289'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    t, y, yerr = np.genfromtxt('example_star.csv', delimiter=',', unpack=True)\n",
    "    name = 'example'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f74607efa1df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do some aggressive sigma clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Do some aggressive sigma clipping\n",
    "m = np.ones_like(y, dtype=bool)\n",
    "while True:\n",
    "    mu = np.nanmean(y[m])\n",
    "    sig = np.nanstd(y[m])\n",
    "    m0 = y - mu < 3 * sig\n",
    "    if np.all(m0 == m):\n",
    "        break\n",
    "    m = m0\n",
    "\n",
    "m = m*np.isfinite(y)*np.isfinite(yerr)*np.isfinite(t)\n",
    "t_orig, y_orig, yerr_orig = np.copy(t), np.copy(y), np.copy(yerr)\n",
    "f = lambda x: np.ascontiguousarray(x, dtype=np.float64)\n",
    "t, y, yerr = map(f, [t[m], y[m], yerr[m]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (len(t_orig), len(y_orig))\n",
    "plt.plot(t_orig, y_orig, '.')\n",
    "plt.plot(t, y, '.')\n",
    "#plt.xlim(320, 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First guess at the period\n",
    "fmin = max([2./(t[-1]-t[0]),0.02] )\n",
    "freq = np.linspace(fmin, 10.0, 5000)\n",
    "model = LombScargle(t, y)\n",
    "power = model.power(freq, method=\"fast\", normalization=\"psd\")\n",
    "power /= len(t)\n",
    "\n",
    "period = 1.0 / freq[np.argmax(power)]\n",
    "print(\"LS period\", period)\n",
    "\n",
    "plt.plot(1.0 / freq, power, \"k\")\n",
    "plt.axvline(period)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t % period, y, \".k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#t, y, yerr = t_orig, y_orig, yerr_orig\n",
    "min_period = period * 0.8\n",
    "max_period = period / 0.8\n",
    "\n",
    "gp = get_rotation_gp(t, y, yerr,\n",
    "                     period, min_period, max_period)\n",
    "gp.compute(t, yerr)\n",
    "print len(t), np.sum(y), np.sum(yerr)\n",
    "print period, min_period, max_period\n",
    "print(gp.log_likelihood(y))\n",
    "gp.get_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neg_log_like(params, y, gp, m):\n",
    "    gp.set_parameter_vector(params)\n",
    "    return -gp.log_likelihood(y[m])\n",
    "\n",
    "def grad_neg_log_like(params, y, gp, m):\n",
    "    gp.set_parameter_vector(params)\n",
    "    return -gp.grad_log_likelihood(y[m])[1]\n",
    "\n",
    "\n",
    "# Do another round of sigma clipping using the GP model\n",
    "# freeze the rotation period so it doesn't fit flares\n",
    "gp.freeze_parameter(\"kernel:terms[2]:log_P\")\n",
    "#gp.freeze_parameter(\"kernel:terms[0]:log_S0\")\n",
    "#gp.freeze_parameter(\"kernel:terms[0]:log_omega0\")\n",
    "#gp.freeze_parameter(\"kernel:terms[1]:log_sigma\")\n",
    "#gp.freeze_parameter(\"kernel:terms[2]:log_a\")\n",
    "#gp.freeze_parameter(\"kernel:terms[2]:log_Q2\")\n",
    "#gp.freeze_parameter(\"kernel:terms[2]:log_Q1\")\n",
    "\n",
    "initial_params = gp.get_parameter_vector()\n",
    "bounds = gp.get_parameter_bounds()\n",
    "\n",
    "# t, y, yerr = t_orig, y_orig, yerr_orig\n",
    "m = np.ones(len(t), dtype=bool)\n",
    "for i in range(2):\n",
    "    plt.figure()\n",
    "    plt.plot(t[m], y[m], \".k\")\n",
    "    ylim = plt.gca().get_ylim()\n",
    "\n",
    "    gp.compute(t[m], yerr[m])   ## to figure out the shape of \n",
    "                                ## the array and time stamps\n",
    "                                ## factorizes the covariance matrix\n",
    "    soln = minimize(neg_log_like, initial_params, jac=grad_neg_log_like,\n",
    "                    method=\"L-BFGS-B\", bounds=bounds, args=(y, gp, m))\n",
    "    gp.set_parameter_vector(soln.x) ## this also re-computes\n",
    "    initial_params = soln.x\n",
    "\n",
    "    mu, var = gp.predict(y[m], t, return_var=True)\n",
    "    plt.plot(t, mu, zorder=0)\n",
    "    plt.ylim(ylim)\n",
    "    #plt.ylim(-1,2)\n",
    "    \n",
    "    resid = y - mu\n",
    "    #sig = np.sqrt(np.median(resid**2))\n",
    "    sig = np.sqrt(var + yerr**2)\n",
    "    m0 = resid < 1.3 * sig\n",
    "    print(m0.sum(), m.sum())\n",
    "    if np.all(m0 == m) or (np.abs(m0.sum()- m.sum()) < 3):\n",
    "        break\n",
    "    m = m0\n",
    "\n",
    "gp.thaw_parameter(\"kernel:terms[2]:log_P\")\n",
    "\n",
    "fit_t, fit_y, fit_yerr = t[m], y[m], yerr[m]\n",
    "gp.compute(fit_t, fit_yerr)\n",
    "gp.get_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "omega = np.exp(np.linspace(np.log(0.1), np.log(20), 5000))\n",
    "psd = gp.kernel.get_psd(omega)\n",
    "\n",
    "plt.plot(omega, psd)\n",
    "for k in gp.kernel.terms:\n",
    "    plt.plot(omega, k.get_psd(omega), \"--\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(omega[0], omega[-1])\n",
    "plt.xlabel(\"$\\omega$\")\n",
    "plt.ylabel(\"$S(\\omega)$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(82)\n",
    "def log_prior(params, logperiod, pp=False):\n",
    "    lp = gp.log_prior()\n",
    "    if pp: print lp\n",
    "    p = gp.get_parameter_dict()['kernel:terms[2]:log_P']\n",
    "    period = np.exp(logperiod)\n",
    "    sigma = 0.2\n",
    "    \n",
    "    logperiod_half = logperiod + np.log(0.5)\n",
    "    logperiod_twice = logperiod + np.log(2.)\n",
    "    gaussian_prior = (-1./2.)*((p - logperiod)/(sigma))**2.\n",
    "    gaussian_prior_half = (-1./2.)*((p - logperiod_half)/(sigma))**2.\n",
    "    gaussian_prior_twice = (-1./2.)*((p - logperiod_twice)/(sigma))**2.\n",
    "\n",
    "    lp = lp + 0.5*gaussian_prior + 0.25*gaussian_prior_half + 0.25*gaussian_prior_twice\n",
    "    \n",
    "    if (np.abs(p-logperiod)>0.4) & (np.abs(p-logperiod_half)>0.4) & (np.abs(p-logperiod_twice)>0.4):\n",
    "        return -np.inf\n",
    "    \n",
    "    if pp: print lp\n",
    "    return lp\n",
    "\n",
    "def log_prob(params, logperiod):\n",
    "    gp.set_parameter_vector(params)\n",
    "    lp = log_prior(params, logperiod)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "#     make the noise budget be dominated by the peroidic signal\n",
    "#     if (gp.get_)\n",
    "    return lp + gp.log_likelihood(fit_y)\n",
    "\n",
    "logperiod = gp.get_parameter_dict()['kernel:terms[2]:log_P']\n",
    "initial_params = gp.get_parameter_vector()\n",
    "print \"starting\", gp.log_likelihood(fit_y)\n",
    "print log_prob(initial_params, logperiod)\n",
    "print log_prior(initial_params, logperiod, pp=True)\n",
    "\n",
    "ndim = len(initial_params)\n",
    "nwalkers = 64\n",
    "print(gp.get_parameter_dict()    )\n",
    "\n",
    "# set up initial positions\n",
    "pos = initial_params + 1e-2 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "# but for period start some at the harmonics\n",
    "tmp = [name == 'kernel:terms[2]:log_P' for name in gp.get_parameter_names()]\n",
    "perloc = np.where(tmp)[0][0]\n",
    "for i in range(nwalkers):\n",
    "    myrand = np.random.uniform()\n",
    "    if myrand < 0.25:\n",
    "        pos[i][perloc] = logperiod + np.log(0.5) + 1e-2 * np.random.randn()\n",
    "    elif myrand < 0.5:\n",
    "        pos[i][perloc] = logperiod + np.log(2) + 1e-2 * np.random.randn()\n",
    "            \n",
    "\n",
    "# and make sure none of them are NaNs\n",
    "lp = np.array( [log_prob(pos_i, logperiod) for pos_i in pos] )\n",
    "m = ~np.isfinite(lp)\n",
    "while np.any(m):\n",
    "    print \"val\", pos[i][perloc]\n",
    "    pos[m] = initial_params + 1e-3 * np.random.randn(m.sum(), ndim)\n",
    "    #lp[m] = np.array(list(map(log_prob, pos[m])))\n",
    "    lp[m] = np.array( [log_prob(pos_i, logperiod) for pos_i in pos[m]] )\n",
    "    m = ~np.isfinite(lp)\n",
    "\n",
    "args=[logperiod]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=args)\n",
    "pos, _, _ = sampler.run_mcmc(pos, 500)\n",
    "print \"burn\", gp.log_likelihood(fit_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sampler.reset()\n",
    "#sampler.run_mcmc(pos, 2000);\n",
    "#print \"chain\", gp.log_likelihood(fit_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = np.isfinite(y_orig)*np.isfinite(yerr_orig)*np.isfinite(t_orig)\n",
    "mle = sampler.flatchain[np.argmax(sampler.flatlnprobability)]\n",
    "gp.set_parameter_vector(mle)\n",
    "mu, var = gp.predict(fit_y, t_orig, return_var=True)\n",
    "std = np.sqrt(yerr_orig[m]**2 + var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdist = np.exp(sampler.flatchain[:, 7])\n",
    "pbest = np.median(pdist)\n",
    "               \n",
    "fig = plt.figure(figsize=[11,6])\n",
    "color = \"#ff7f0e\"\n",
    "\n",
    "ax1 = plt.subplot2grid((2, 3), (1, 0), colspan=2, )\n",
    "ax2 = plt.subplot2grid((2, 3), (1, 2), colspan=1, )\n",
    "\n",
    "ax1.fill_between(t_orig[m], mu+std*3, mu-std*3, alpha=0.7, color=color, zorder=1)\n",
    "ax1.plot(t_orig, y_orig, '.-', zorder=0)\n",
    "ax1.set_ylim(-0.02,0.03)\n",
    "xl = [t_orig[0], t_orig[-1]]\n",
    "#if (xl[1]-xl[0]) > 8*pbest:\n",
    "#    xl = [t_orig[0]+16*pbest, t_orig[0]+16*pbest]\n",
    "ax1.set_xlim(xl)\n",
    "ax1.set_xlim(300,320)\n",
    "ax1.set_xlabel('Time (days)', fontsize=14)\n",
    "ax1.set_ylabel('Relative Brighness', fontsize=14)\n",
    "\n",
    "ax2.hist(pdist, 50, histtype=\"step\")\n",
    "ax2.set_xlabel('Rotation Period (days)', fontsize=14)\n",
    "ax2.set_ylabel('Posterior Probability', fontsize=14)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "varnames = gp.get_parameter_dict().keys()\n",
    "samples = sampler.chain[:, :, :].reshape((-1, ndim)) \n",
    "best = map(lambda v: [v[1], v[2]-v[1], v[1]-v[0]], \\\n",
    "                   zip(*np.percentile(samples, [16, 50, 84], axis=0))) ## arranged: [50th, uppe\n",
    "mydict = {}\n",
    "labels = [None]*ndim\n",
    "for i in range(len(varnames)):\n",
    "    vv = varnames[i][16:]\n",
    "    if vv == 'mix_par':\n",
    "        vv = 'mix'\n",
    "    else:\n",
    "        vv = vv.replace('log_','log(')+')'\n",
    "    mydict[vv] = best[i]\n",
    "    labels[i] = vv\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#messing around to try and visualize what's going on\n",
    "# but this doesn't work because each term is trying to explain\n",
    "# all of what's going on since it depends on the input y values\n",
    "from mixterm import MixtureOfSHOsTerm\n",
    "kernel = gp.get_parameter_dict(include_frozen=True)\n",
    "\n",
    "period_kernel = MixtureOfSHOsTerm(\n",
    "        log_a=kernel['kernel:terms[2]:log_a'], ## amplitude of the main peak\n",
    "        log_Q1=kernel['kernel:terms[2]:log_Q1'], ## decay timescale of the main peak (width of the spike in the FT)\n",
    "        mix_par= kernel['kernel:terms[2]:mix_par'], ## height of second peak relative to first peak\n",
    "        log_Q2=kernel['kernel:terms[2]:log_Q2'], ## decay timescale of the second peak\n",
    "        log_P=kernel['kernel:terms[2]:log_P'], ## period (second peak is constrained to twice this)\n",
    "        bounds=dict(\n",
    "            log_a=(-20.0, 10.0),\n",
    "            log_Q1=(0., 10.0),\n",
    "            mix_par=(-5.0, 10.0),\n",
    "            log_Q2=(0., 10.0),\n",
    "            log_P=(None, None), # np.log(min_period), np.log(max_period)),\n",
    "        )\n",
    "    )\n",
    "period_gp = celerite.GP(kernel=period_kernel, mean=np.nanmean(fit_y))\n",
    "period_gp.compute(fit_t, fit_yerr)\n",
    "mu_period, _ = period_gp.predict(fit_y, t_orig[m], return_var=False)\n",
    "\n",
    "\n",
    "basic_kernel = terms.SHOTerm(\n",
    "    log_S0=kernel['kernel:terms[0]:log_S0'],\n",
    "    log_Q=kernel['kernel:terms[0]:log_Q'],\n",
    "    log_omega0=kernel['kernel:terms[0]:log_omega0'],\n",
    "    bounds=dict(\n",
    "        log_S0=(-20.0, 10.0),\n",
    "        log_omega0=(np.log(2*np.pi/(period*50.)), np.log(2*np.pi/(period*10))),\n",
    "    ),\n",
    ")\n",
    "basic_gp = celerite.GP(kernel=basic_kernel, mean=np.nanmean(fit_y))\n",
    "basic_gp.compute(fit_t, fit_yerr)\n",
    "mu_basic, _ = basic_gp.predict(fit_y, t_orig[m], return_var=False)\n",
    "\n",
    "jitter_kernel = terms.JitterTerm(log_sigma=kernel['kernel:terms[1]:log_sigma'],\n",
    "                               bounds=[(-20,20)])\n",
    "jitter_gp = celerite.GP(kernel=jitter_kernel, mean=np.nanmean(fit_y))\n",
    "jitter_gp.compute(fit_t, fit_yerr)\n",
    "mu_jitter, _ = jitter_gp.predict(fit_y, t_orig[m], return_var=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[11,6])\n",
    "color = \"#ff7f0e\"\n",
    "ax1 = plt.subplot()\n",
    "ax1.plot(t_orig[m], mu_period, alpha=0.7, lw=3, color='C0', zorder=1, label='SHO Mixture')\n",
    "ax1.plot(t_orig[m], mu_basic, alpha=0.7, lw=3, color='C4', zorder=1, label='SHO')\n",
    "ax1.plot(t_orig[m], mu_jitter, alpha=0.7, lw=3, color='C3', zorder=1, label='Jitter')\n",
    "ax1.plot(t_orig[m], mu, \":\", alpha=0.7, lw=3, color=color, zorder=2)\n",
    "#ax1.plot(t_orig, y_orig, '.-', zorder=0)\n",
    "ax1.set_xlim(0,10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make the base corner plot\n",
    "figure = corner.corner(samples)\n",
    "\n",
    "# Extract the axes\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "\n",
    "# Loop over the diagonal\n",
    "for i in range(ndim):\n",
    "    ax = axes[i, i]\n",
    "    print ax\n",
    "    low, high = np.percentile(samples[:,i], [2,98])\n",
    "    print low, high\n",
    "    ax.set_xlim(low, high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "toplot = np.array(np.linspace(0,len(sampler.chain[0,:,0])-1,1000), dtype=int)\n",
    "plt.plot(sampler.chain[:, toplot, 7].T, color=\"k\", alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(0.5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
